{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32]) torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "#Create X and Y arrays\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Initialize the final arrays correctly\n",
    "X_final_array = np.empty((0, 3072))  # CIFAR-10 has 3072 features (32x32x3)\n",
    "Y_final_array = np.empty((0,))  # Correct initialization for Y\n",
    "\n",
    "for i in range(1, 6):\n",
    "    # The path to the data\n",
    "    url = '/Users/josemiguelvilchesfierro/Downloads/cifar-10-batches-py/data_batch_'+str(i)\n",
    "\n",
    "    # Load the data\n",
    "    unpickle_data = unpickle(url)\n",
    "    \n",
    "    # This is the 'data' which is in uint8 format\n",
    "    X_temp = unpickle_data[b'data']\n",
    "    Y_temp = np.array(unpickle_data[b'labels'])  # Convert Y_temp to a NumPy array\n",
    "    \n",
    "    # Concatenate temp_array to final_array along axis 0\n",
    "    X_final_array = np.concatenate((X_final_array, X_temp), axis=0)\n",
    "    Y_final_array = np.concatenate((Y_final_array, Y_temp), axis=0)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X_final_array)\n",
    "X = X.view(-1, 3, 32, 32)  # Reshape to (batch_size, channels, height, width)\n",
    "Y = torch.tensor(Y_final_array)\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 3, 32, 32]) torch.Size([40000])\n",
      "torch.Size([5000, 3, 32, 32]) torch.Size([5000])\n",
      "torch.Size([5000, 3, 32, 32]) torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "#Create tain, dev and test data\n",
    "\n",
    "#Define the splits\n",
    "first_split = int(0.8 * len(X))\n",
    "second_split = int(0.9 * len(X))\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "Xtr, Ytr = X[:first_split], Y[:first_split]\n",
    "Xdev, Ydev = X[first_split:second_split], Y[first_split:second_split]\n",
    "Xte, Yte = X[second_split:], Y[second_split:]\n",
    "\n",
    "print (Xtr.shape, Ytr.shape)    \n",
    "print (Xdev.shape, Ydev.shape)\n",
    "print (Xte.shape, Yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [5.0..254.0].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [20.0..255.0].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.0..234.0].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..254.0].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing pictures\n",
    "\n",
    "# Create a figure with subplots to display multiple images\n",
    "plt.figure(figsize=(10, 5))  # Adjust the size as needed\n",
    "\n",
    "# Loop to display 10 images\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)  # Create a 2x5 grid of subplots\n",
    "    img = X[i].reshape(3, 32, 32).permute(1, 2, 0)  # Reshape and permute the image tensor\n",
    "    plt.imshow(img.detach().numpy())  # Convert to NumPy and display\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()  # Show all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = torch.randn(input_size, output_size, dtype=torch.float32) * 0.3\n",
    "        self.biases = torch.zeros(output_size, dtype=torch.float32) * 0.3\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input.float()\n",
    "        self.output = torch.mm(self.input, self.weights) + self.biases\n",
    "        return self.output\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weights] if self.biases is None else [self.weights, self.biases]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Define the improved convolutional block with batch norm\n",
    "class convolutional:\n",
    "    def __init__(self, input_depth, n_kernels, kernel_size):\n",
    "        self.kernels = torch.randn(n_kernels, input_depth, kernel_size, kernel_size, dtype=torch.float32)\n",
    "        self.biases = torch.zeros(n_kernels, dtype=torch.float32)\n",
    "        init.xavier_uniform_(self.kernels)  # Use Xavier initialization for weights\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.input = input.float()\n",
    "        self.output = F.conv2d(self.input, self.kernels, self.biases, stride=1, padding=1)\n",
    "        return self.output\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.kernels, self.biases]\n",
    "#----------------------------------------------------------------------\n",
    "class BatchNorm:\n",
    "    def __init__(self, n_kernels):\n",
    "        self.bn = torch.nn.BatchNorm2d(n_kernels)  # Ensure n_kernels matches the output of conv layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.bn(x)\n",
    "\n",
    "    def parameters(self):\n",
    "        return list(self.bn.parameters())  \n",
    "#----------------------------------------------------------------------\n",
    "# Max Pool and ReLU class remain the same\n",
    "\n",
    "class improved_sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "#----------------------------------------------------------------------\n",
    "class ReLU:\n",
    "    def __call__(self, x):\n",
    "        return torch.relu(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "class reshape():\n",
    "    def __init__(self, output_shape):\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print(f\"Reshape Input shape : {input.shape}\")\n",
    "        batch_size = input.shape[0]\n",
    "        self.output = input.view(batch_size, -1)  # Flatten the input dynamically\n",
    "        #print(f\"Reshape Output shape : {self.output.shape}\")\n",
    "        return self.output\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "  \n",
    "class Dropout:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p  # Probability of dropping neurons\n",
    "\n",
    "    def __call__(self, x, training=True):\n",
    "        return self.forward(x, training)\n",
    "\n",
    "    def forward(self, input, training=True):\n",
    "        if not training:\n",
    "            return input  # During evaluation, dropout is not applied\n",
    "        \n",
    "        # Create a mask with the same shape as the input, filled with random values from 0 to 1\n",
    "        mask = torch.rand(input.shape, dtype=input.dtype, device=input.device)\n",
    "        \n",
    "        # Apply dropout: Set values to 0 where mask values are less than dropout probability\n",
    "        # and scale the remaining neurons by 1/(1 - p) to keep the expected sum of activations constant\n",
    "        mask = (mask >= self.p).float() / (1 - self.p)\n",
    "        \n",
    "        # Apply the mask to the input\n",
    "        output = input * mask\n",
    "        return output\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "class maxpool:\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        batch_size, depth, height, width = input.shape\n",
    "        \n",
    "        # Define the stride as the kernel size (no overlap between pooling windows)\n",
    "        stride = self.kernel_size\n",
    "        \n",
    "        # Calculate the output height and width after pooling\n",
    "        out_height = height // self.kernel_size\n",
    "        out_width = width // self.kernel_size\n",
    "\n",
    "        # Initialize the output tensor\n",
    "        output = torch.zeros((batch_size, depth, out_height, out_width), dtype=input.dtype)\n",
    "\n",
    "        # Iterate over the input tensor\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                # Select the patch corresponding to the current pooling window\n",
    "                h_start = i * stride\n",
    "                h_end = h_start + self.kernel_size\n",
    "                w_start = j * stride\n",
    "                w_end = w_start + self.kernel_size\n",
    "\n",
    "                # Apply max pooling (take the maximum value within the pooling window)\n",
    "                patch = input[:, :, h_start:h_end, w_start:w_end]\n",
    "                output[:, :, i, j] = patch.max(dim=-1)[0].max(dim=-1)[0]\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147914\n"
     ]
    }
   ],
   "source": [
    "# Define the improved sequential model\n",
    "model = improved_sequential([\n",
    "    convolutional(3, 32, 3), BatchNorm(32), ReLU(),  # First Conv block with 32 kernels\n",
    "    maxpool(2),\n",
    "    convolutional(32, 64, 3), BatchNorm(64), ReLU(),  # Second Conv block with 64 kernels\n",
    "    maxpool(2),\n",
    "    convolutional(64, 128, 3), BatchNorm(128), ReLU(),  # Third Conv block with 128 kernels\n",
    "    maxpool(2),\n",
    "    reshape([128 * 4 * 4]),  # Adjust based on final feature map size\n",
    "    Dropout(0.5),\n",
    "    linear(128 * 4 * 4, 512), ReLU(),  # Fully connected layers\n",
    "    Dropout(0.5),\n",
    "    linear(512, 10)\n",
    "])\n",
    "\n",
    "#Set parameters to train\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "\n",
    "# Define optimizer (Adam)\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n",
    "# Define scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.001)  # Reduce LR every 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200000], Loss: 290.1011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     19\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m lre \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 200000\n",
    "batch_size = 32\n",
    "lossi = [] \n",
    "lrei = []\n",
    "steps = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "    # Forward pass\n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb.long())  # Convert target labels to Long data type\n",
    "    \n",
    "    # Zero gradients, backpropagate, and update weights\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    lre = 0.0001 if i < 100000 else 0.0001\n",
    "    with torch.no_grad():\n",
    "        for p in parameters:\n",
    "            p -= p.grad * lre  # Update weights using learning rate\n",
    "    \n",
    "    lossi.append(loss.item())\n",
    "    lrei.append(lre)\n",
    "    steps.append(i)\n",
    "\n",
    "    # Print the loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch [{epoch}/{max_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1,1000).mean(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9480\n",
      "val loss: 1.9592\n"
     ]
    }
   ],
   "source": [
    "#Test the model with dev data\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(value):\n",
    "    x,y = {'train': (Xtr, Ytr), 'val': (Xdev, Ydev)}[value]\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y.long())\n",
    "    print(f'{value} loss: {loss.item():.4f}')\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Performance Log\n",
    "\n",
    "1) First version    : kernel_size = 3, n_kernels = 2, parameters = 13662, max_steps = 20000 --> train loss: 2.2277 | val loss: 2.2389\n",
    "1) First version (2): kernel_size = 3, n_kernels = 2, parameters = 20542, max_steps = 20000 --> train loss: 2.4063 | val loss: 2.4111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.26% (1263/5000 correct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.259999999999998"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# During evaluation\n",
    "def evaluate_model(model, X_eval, Y_eval):\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits = model(X_eval)\n",
    "\n",
    "        # Apply softmax to logits to get probabilities\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Get predicted class by taking argmax of the probabilities\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "\n",
    "        correct_predictions = (predicted_labels == Y_eval).sum().item()\n",
    "        total_samples = Y_eval.shape[0]\n",
    "        accuracy = correct_predictions / total_samples * 100\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}% ({correct_predictions}/{total_samples} correct)\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(model, Xte, Yte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
