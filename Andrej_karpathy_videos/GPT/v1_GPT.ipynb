{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-03 13:38:37--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘/Users/josemiguelvilchesfierro/input.txt’\n",
      "\n",
      "/Users/josemiguelvi 100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-10-03 13:38:38 (9.91 MB/s) - ‘/Users/josemiguelvilchesfierro/input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O ~/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('/Users/josemiguelvilchesfierro/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters:  65\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "list_ch = sorted(list(set(text)))\n",
    "vocab_size = len(list_ch)\n",
    "print(\"number of unique characters: \", len(list_ch))\n",
    "print(list_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42]\n",
      "hello World\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(list_ch)}\n",
    "itos = {i:ch for i,ch in enumerate(list_ch)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda h: ''.join([itos[i] for i in h])\n",
    "\n",
    "encoded = encode('hello World')\n",
    "decoded = decode(encode('hello World'))\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#Encode dataset\n",
    "text_encode = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset\n",
    "n = int(len(text_encode) * 0.9)\n",
    "train = text_encode[:n]\n",
    "valid = text_encode[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "When X --> tensor([18]) then Y --> 47\n",
      "When X --> tensor([18, 47]) then Y --> 56\n",
      "When X --> tensor([18, 47, 56]) then Y --> 57\n",
      "When X --> tensor([18, 47, 56, 57]) then Y --> 58\n",
      "When X --> tensor([18, 47, 56, 57, 58]) then Y --> 1\n",
      "When X --> tensor([18, 47, 56, 57, 58,  1]) then Y --> 15\n",
      "When X --> tensor([18, 47, 56, 57, 58,  1, 15]) then Y --> 47\n",
      "When X --> tensor([18, 47, 56, 57, 58,  1, 15, 47]) then Y --> 58\n"
     ]
    }
   ],
   "source": [
    "# x and y\n",
    "block_size = 8\n",
    "X = train[:block_size]\n",
    "Y = train[1:block_size +1]\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = X[:i+1]\n",
    "    target = Y[i]\n",
    "    print(f\"When X --> {context} then Y --> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xb.shape=torch.Size([4, 16])\n",
      "Yb.shape=torch.Size([4, 16])\n",
      "-----------------\n",
      "When X --> tensor([21]) then Y --> 27\n",
      "When X --> tensor([21, 27]) then Y --> 24\n",
      "When X --> tensor([21, 27, 24]) then Y --> 13\n",
      "When X --> tensor([21, 27, 24, 13]) then Y --> 26\n",
      "When X --> tensor([21, 27, 24, 13, 26]) then Y --> 33\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33]) then Y --> 31\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31]) then Y --> 10\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10]) then Y --> 0\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0]) then Y --> 32\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32]) then Y --> 59\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59]) then Y --> 57\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57]) then Y --> 46\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57, 46]) then Y --> 6\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57, 46,  6]) then Y --> 1\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57, 46,  6,  1]) then Y --> 58\n",
      "When X --> tensor([21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57, 46,  6,  1, 58]) then Y --> 59\n",
      "When X --> tensor([53]) then Y --> 59\n",
      "When X --> tensor([53, 59]) then Y --> 57\n",
      "When X --> tensor([53, 59, 57]) then Y --> 1\n",
      "When X --> tensor([53, 59, 57,  1]) then Y --> 51\n",
      "When X --> tensor([53, 59, 57,  1, 51]) then Y --> 43\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43]) then Y --> 52\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52]) then Y --> 0\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0]) then Y --> 13\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13]) then Y --> 56\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56]) then Y --> 43\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43]) then Y --> 1\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1]) then Y --> 39\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1, 39]) then Y --> 58\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1, 39, 58]) then Y --> 1\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1, 39, 58,  1]) then Y --> 58\n",
      "When X --> tensor([53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1, 39, 58,  1, 58]) then Y --> 46\n",
      "When X --> tensor([50]) then Y --> 6\n",
      "When X --> tensor([50,  6]) then Y --> 1\n",
      "When X --> tensor([50,  6,  1]) then Y --> 57\n",
      "When X --> tensor([50,  6,  1, 57]) then Y --> 47\n",
      "When X --> tensor([50,  6,  1, 57, 47]) then Y --> 56\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56]) then Y --> 8\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8]) then Y --> 1\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1]) then Y --> 18\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18]) then Y --> 39\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39]) then Y --> 56\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56]) then Y --> 43\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43]) then Y --> 1\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43,  1]) then Y --> 63\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43,  1, 63]) then Y --> 53\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43,  1, 63, 53]) then Y --> 59\n",
      "When X --> tensor([50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43,  1, 63, 53, 59]) then Y --> 1\n",
      "When X --> tensor([58]) then Y --> 46\n",
      "When X --> tensor([58, 46]) then Y --> 1\n",
      "When X --> tensor([58, 46,  1]) then Y --> 57\n",
      "When X --> tensor([58, 46,  1, 57]) then Y --> 53\n",
      "When X --> tensor([58, 46,  1, 57, 53]) then Y --> 6\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6]) then Y --> 1\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1]) then Y --> 46\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46]) then Y --> 53\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53]) then Y --> 50\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50]) then Y --> 63\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63]) then Y --> 1\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1]) then Y --> 57\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1, 57]) then Y --> 47\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1, 57, 47]) then Y --> 56\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1, 57, 47, 56]) then Y --> 11\n",
      "When X --> tensor([58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1, 57, 47, 56, 11]) then Y --> 1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 16\n",
    "def get_batch(split):\n",
    "    data = train if split == 'train' else valid\n",
    "    ix = torch.randint(len(data)- block_size, (batch_size,))\n",
    "    X = torch.stack([data[   i : i+block_size   ] for i in ix])\n",
    "    Y = torch.stack([data[i + 1: i+block_size +1] for i in ix])\n",
    "    return X, Y\n",
    "\n",
    "Xb, Yb = get_batch('train')\n",
    "print(f\"{Xb.shape=}\")\n",
    "print(f\"{Yb.shape=}\")\n",
    "print(\"-----------------\")\n",
    "\n",
    "for i in range(batch_size):\n",
    "    for j in range(block_size):\n",
    "        context = Xb[i, :j+1]\n",
    "        target = Yb[i, j]\n",
    "        print(f\"When X --> {context} then Y --> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 27, 24, 13, 26, 33, 31, 10,  0, 32, 59, 57, 46,  6,  1, 58, 31, 56,\n",
       "         12, 55, 28,  7, 29, 35, 49, 58],\n",
       "        [53, 59, 57,  1, 51, 43, 52,  0, 13, 56, 43,  1, 39, 58,  1, 58, 31,  0,\n",
       "         60, 60, 47, 37, 16, 17, 57, 62],\n",
       "        [50,  6,  1, 57, 47, 56,  8,  1, 18, 39, 56, 43,  1, 63, 53, 59, 16,  4,\n",
       "         55, 29, 16, 15, 34,  4, 53, 48],\n",
       "        [58, 46,  1, 57, 53,  6,  1, 46, 53, 50, 63,  1, 57, 47, 56, 11,  4, 29,\n",
       "         10, 17, 22, 46,  3, 44, 30, 18]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguajeModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_tokken = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets= None):        \n",
    "        #Embedding tokens and targets in a 3d tensor\n",
    "        logits = self.embedding_tokken(idx) # B T C [4x 8 x 65]\n",
    "\n",
    "        #Reshape the tensor to 2d for cross entropy\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B , T, C = logits.shape\n",
    "            logits = logits.view(B*T , C) #[32 x 65]\n",
    "            targets = targets.view(B*T) #[32]\n",
    "            #Calculate loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the prediction\n",
    "            logits, loss = self(idx) # [B x T x C] because targets is None [4 x 8 x 65]\n",
    "            #get the last token\n",
    "            logits = logits[:, -1, :] # Becomes [B x C] [4 x 65]\n",
    "            #softmax\n",
    "            probs = F.softmax(logits, dim=1) \n",
    "            #sample\n",
    "            new_token = torch.multinomial(probs, 1)\n",
    "            #append to the sequence\n",
    "            idx = torch.cat([idx, new_token], dim=1) # B x T+1   \n",
    "\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguajeModel(vocab_size)\n",
    "model.generate(Xb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimier = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.947575569152832\n",
      "loss: 2.7999722957611084\n",
      "loss: 2.659029245376587\n",
      "loss: 2.524958848953247\n",
      "loss: 2.3979098796844482\n",
      "loss: 2.277965784072876\n",
      "loss: 2.165147304534912\n",
      "loss: 2.0594098567962646\n",
      "loss: 1.960646390914917\n",
      "loss: 1.868687629699707\n",
      "loss: 1.7833110094070435\n",
      "loss: 1.7042453289031982\n",
      "loss: 1.6311838626861572\n",
      "loss: 1.5637930631637573\n",
      "loss: 1.5017261505126953\n",
      "loss: 1.4446297883987427\n",
      "loss: 1.3921564817428589\n",
      "loss: 1.3439686298370361\n",
      "loss: 1.299744725227356\n",
      "loss: 1.2591819763183594\n",
      "loss: 1.2219980955123901\n",
      "loss: 1.187931776046753\n",
      "loss: 1.1567413806915283\n",
      "loss: 1.1282044649124146\n",
      "loss: 1.1021153926849365\n",
      "loss: 1.0782831907272339\n",
      "loss: 1.0565308332443237\n",
      "loss: 1.0366913080215454\n",
      "loss: 1.0186084508895874\n",
      "loss: 1.0021346807479858\n",
      "loss: 0.9871307611465454\n",
      "loss: 0.9734655618667603\n",
      "loss: 0.961016833782196\n",
      "loss: 0.9496700167655945\n",
      "loss: 0.9393194913864136\n",
      "loss: 0.9298681020736694\n",
      "loss: 0.9212271571159363\n",
      "loss: 0.9133164882659912\n",
      "loss: 0.9060633182525635\n",
      "loss: 0.899402916431427\n",
      "loss: 0.8932767510414124\n",
      "loss: 0.8876331448554993\n",
      "loss: 0.882425844669342\n",
      "loss: 0.8776140213012695\n",
      "loss: 0.8731606602668762\n",
      "loss: 0.8690335750579834\n",
      "loss: 0.8652033805847168\n",
      "loss: 0.8616442680358887\n",
      "loss: 0.8583329319953918\n",
      "loss: 0.8552485704421997\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "for i in range(5000):\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {i} -- Train Loss: {losses['train']:.2f} -- Valid Loss: {losses['valid']:.2f}\")\n",
    "\n",
    "    #forward step\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(Xb, Yb)\n",
    "\n",
    "    #backward step\n",
    "    optimier.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimier.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANUS:\n",
      "Ty sousire ar; sol, -wNUS:CDn\n",
      "Ar. men\n",
      "Are d, C-bYLAr. sh tu yousir; s soly Fat men\n",
      "ANUS:\n",
      "T'QjQ'BS:\n",
      "Are hush yous Far. Ml, h, thol, thou h yol, tu me so, y men\n",
      "Tu!P!zPe sho, ar; ar. mY-jKuso&xqxZQyousous t aren\n",
      "Tush at tth siren\n",
      "Tush, sire yol, t sh h men\n",
      "Tu h, me me t yo, Fare ath, FathRl, Fare tus at men\n",
      "Ar. sB$KpUS:\n",
      "ANt atholyHqMOLAr; shol, you ho, sous t Faren\n",
      "ANUS:\n",
      "AV; at t sir. ywo, th \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "generate = model.generate(idx, 400)[0].tolist()\n",
    "print(decode(generate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
