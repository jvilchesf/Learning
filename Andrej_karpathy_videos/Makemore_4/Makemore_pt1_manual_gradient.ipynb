{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Replace with the URL you copied\n",
    "url = 'https://raw.githubusercontent.com/jvilchesf/Learning/main/Andrej_karpathy_videos/Makemore/names.txt'\n",
    "\n",
    "response = requests.get(url)\n",
    "words = response.text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionaries\n",
    "alphabet = sorted(list(set(''.join(words))))\n",
    "itos = {idx + 1: ch for idx, ch in enumerate(alphabet)} \n",
    "itos[0] = '.'\n",
    "stoi = {s : i  for i, s in itos.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "#Creating the dataset\n",
    "\n",
    "block_size = 3\n",
    "vocab_size = len(itos)\n",
    "def create_dataset(words): \n",
    "    X = []\n",
    "    Y = []\n",
    "    for word in words:\n",
    "        context = block_size * [0]\n",
    "\n",
    "        for i in word + '.':\n",
    "            idx = stoi[i]\n",
    "            Y.append(idx)\n",
    "            X.append(context)\n",
    "            #print(f\"{context} ---> {i}\")\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X,Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(len(words) * 0.8)\n",
    "n2 = int(len(words) * 0.9)\n",
    "\n",
    "Xtr, Ytr = create_dataset(words[:n1])\n",
    "Xdev, Ydev = create_dataset(words[n1:n2])\n",
    "Xte, Yte = create_dataset(words[n2:])\n",
    "\n",
    "print (Xtr.shape, Ytr.shape)    \n",
    "print (Xdev.shape, Ydev.shape)\n",
    "print (Xte.shape, Yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters =  12297\n"
     ]
    }
   ],
   "source": [
    "#Declare parameters w1, w2, b1, b2\n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C  = torch.randn((vocab_size, n_embd),          generator=g)\n",
    "# Input layer\n",
    "W1 = torch.randn((block_size * n_embd, n_hidden),       generator=g) / (5/3) / (block_size * n_embd) ** 0.5 \n",
    "b1 = torch.randn(n_hidden,                              generator=g) * 0.01\n",
    "#Output layer\n",
    "W2 = torch.randn(n_hidden, vocab_size,                  generator=g)  * 0.1 #it is multiply by 0.1 to get smaller logits and smaller loss\n",
    "b2 = torch.randn(vocab_size,                            generator=g)  * 0 # it is declare as 0 for the model initialization\n",
    "\n",
    "\n",
    "#Batch normalization parameters\n",
    "bngain = torch.ones((1,n_hidden))\n",
    "bnbias = torch.zeros((1,n_hidden))\n",
    "bnmean_running = torch.zeros((1,n_hidden))\n",
    "bnstd_running = torch.ones((1,n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2,bngain, bnbias]\n",
    "print(f\"Number of parameters =  {sum(p.numel() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7900, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# -----------------\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1/n\n",
    "\n",
    "dprobs = (1 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims = True)\n",
    "dcounts = counts_sum_inv * dprobs # [32 x 1] x [32 x 27] = [32 x 27]\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv  # d/dx x**-1 --->  -1 / x**2\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits =  dnorm_logits.clone()\n",
    "dlogit_maxes = -dnorm_logits.sum(1, keepdims = True)\n",
    "dlogits += F.one_hot((logits.max(1).indices), vocab_size) * dlogit_maxes\n",
    "dh = dlogits @ W2.t()\n",
    "dW2 = h.t() @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims = True)\n",
    "dbnraw = bngain * dhpreact  \n",
    "dbnbias = dhpreact.sum(0, keepdims = True)\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims = True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar =  (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0 / (n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = -dbndiff.sum(0)\n",
    "dhprebn += 1.0 /n * torch.ones_like(hprebn) * dbnmeani\n",
    "dembcat = dhprebn @ W1.t()\n",
    "dW1 = embcat.t() @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "\n",
    "# -----------------\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "#cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.790031909942627 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: False | approximate: True  | maxdiff: 5.122274160385132e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1 \n",
    "dlogits /= n\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0124, 0.1804, 0.0151, 0.0345, 0.0480, 0.0186, 0.0121, 0.0137, 0.0294,\n",
       "        0.0264, 0.0725, 0.0085, 0.0220, 0.0063, 0.0194, 0.0199, 0.0345, 0.0056,\n",
       "        0.0025, 0.0191, 0.1214, 0.0557, 0.0708, 0.0143, 0.0041, 0.0666, 0.0663],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.0268e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142e13150>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20, 5))\n",
    "plt.imshow(dlogits.detach(), cmap = 'grey')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
