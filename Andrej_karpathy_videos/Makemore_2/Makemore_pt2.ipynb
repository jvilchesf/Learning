{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "# Replace with the URL you copied\n",
    "url = 'https://raw.githubusercontent.com/jvilchesf/Learning/main/Andrej_karpathy_videos/Makemore/names.txt'\n",
    "\n",
    "response = requests.get(url)\n",
    "words = response.text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to convert from index to character\n",
    "alphabet = sorted(set(\"\".join(words)))\n",
    "itos = {idx:ch for idx,ch in enumerate(alphabet)}\n",
    "stoi = {ch:idx for idx,ch in enumerate(alphabet)}\n",
    "\n",
    "itos[26] = '.'\n",
    "stoi['.'] = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] -> e\n",
      "[0, 0, 4] -> m\n",
      "[0, 4, 12] -> m\n",
      "[4, 12, 12] -> a\n",
      "[12, 12, 0] -> .\n",
      "-----------------\n",
      "[0, 0, 0] -> o\n",
      "[0, 0, 14] -> l\n",
      "[0, 14, 11] -> i\n",
      "[14, 11, 8] -> v\n",
      "[11, 8, 21] -> i\n",
      "[8, 21, 8] -> a\n",
      "[21, 8, 0] -> .\n",
      "-----------------\n",
      "[0, 0, 0] -> a\n",
      "[0, 0, 0] -> v\n",
      "[0, 0, 21] -> a\n",
      "[0, 21, 0] -> .\n",
      "-----------------\n",
      "[0, 0, 0] -> i\n",
      "[0, 0, 8] -> s\n",
      "[0, 8, 18] -> a\n",
      "[8, 18, 0] -> b\n",
      "[18, 0, 1] -> e\n",
      "[0, 1, 4] -> l\n",
      "[1, 4, 11] -> l\n",
      "[4, 11, 11] -> a\n",
      "[11, 11, 0] -> .\n",
      "-----------------\n",
      "[0, 0, 0] -> s\n",
      "[0, 0, 18] -> o\n",
      "[0, 18, 14] -> p\n",
      "[18, 14, 15] -> h\n",
      "[14, 15, 7] -> i\n",
      "[15, 7, 8] -> a\n",
      "[7, 8, 0] -> .\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#Creating the dataset\n",
    "block_size = 3\n",
    "context = []\n",
    "X , Y = [], []\n",
    "for w in words[:5]: \n",
    "\n",
    "    context = block_size * [0] \n",
    "\n",
    "    for i in w + '.':\n",
    "        idx = stoi[i]\n",
    "        X.append(context)\n",
    "        Y.append(idx)\n",
    "        print(f\"{context} -> {i}\")\n",
    "        context = context[1:] + [idx]\n",
    "    print('-----------------')\n",
    "\n",
    "X = torch.tensor(X)    \n",
    "Y = torch.tensor(Y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))\n",
    "emb = C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the hidden layer\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn((100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the input by the weights and add the bias\n",
    "# Apply activation function tahn\n",
    "h = torch.tanh((emb.view(-1,6) @ W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for a second layer\n",
    "W2 = torch.randn((100,27))\n",
    "b2 = torch.randn((27))\n",
    "\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(550.3340)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing the loss function        \n",
    "loss = -probs[range(len(Y)),Y].log().sum()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = 32 x 6\n",
    "# w1 = 6 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
